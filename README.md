# LLAMA-3.1-8b-financial-news-fine-tune
LLama 3.1 Fine tune using LoRA (Low Rank Adaptation) and 4bit quantization for memory-efficient fine-tuning with limited computational resources.

## Goal 

Use a Large Language model for financial news analysis.

## Challenges

Due to LLMs large parameter nature, it is computationally difficult to adapt (fine-tune) them. Moreover, it is   
